{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import pydot\n",
        "import uuid"
      ],
      "metadata": {
        "id": "60P7FpJKpV44"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fUKWEEJ-oGDh"
      },
      "outputs": [],
      "source": [
        "def read_data():\n",
        "  data = pd.read_csv('titanic-homework.csv')\n",
        "  data = data.drop(columns=['PassengerId', 'Name'])\n",
        "  for i in data['Age']:\n",
        "    if i <= 20:\n",
        "      data['Age'] = data['Age'].replace([i], \"young (0-20)\")\n",
        "    elif i > 20 and i <= 40:\n",
        "      data['Age'] = data['Age'].replace([i], \"middle (21-40)\")\n",
        "    else:\n",
        "      data['Age'] = data['Age'].replace([i], \"old (41-100)\")\n",
        "  return data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_total_entropy(data, label):\n",
        "  data_size = data.shape[0]\n",
        "  partial_entropies = []\n",
        "  for i in np.unique(data[label]):\n",
        "    label_class_count = data[data[label] == i].shape[0]\n",
        "    partial_entropies.append((label_class_count/data_size)*np.log2(label_class_count/data_size))\n",
        "  return -sum(partial_entropies)"
      ],
      "metadata": {
        "id": "sDO24hFVzq0b"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_entropy(filtered_data, label):\n",
        "  filtered_data_size = filtered_data.shape[0]\n",
        "  partial_entropies = []\n",
        "  for i in np.unique(filtered_data[\"Survived\"]):\n",
        "    label_class_count = filtered_data[filtered_data[label] == i].shape[0]\n",
        "    if label_class_count == 0:\n",
        "      partial_entropies.append(0)\n",
        "    else:\n",
        "      partial_entropies.append((label_class_count/filtered_data_size)*np.log2(label_class_count/filtered_data_size))\n",
        "  return -sum(partial_entropies)"
      ],
      "metadata": {
        "id": "HSVzPUo50CBU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_conditional_entropy(feature, data, label):\n",
        "  feature_values = data[feature].unique()\n",
        "  data_size = data.shape[0]\n",
        "  conditional_entropies_parts = []\n",
        "  for feature_value in feature_values:\n",
        "    feature_value_data = data[data[feature] == feature_value]\n",
        "    feature_value_count = feature_value_data.shape[0]\n",
        "    feature_value_entropy = calculate_entropy(feature_value_data, label)\n",
        "    feature_value_probability = feature_value_count/data_size\n",
        "    conditional_entropies_parts.append(feature_value_probability * feature_value_entropy)\n",
        "\n",
        "  return sum(conditional_entropies_parts)"
      ],
      "metadata": {
        "id": "mLFGRfpg1g6I"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_gain(feature, data, label):\n",
        "  return calculate_total_entropy(data, label) - calculate_conditional_entropy(feature, data, label)"
      ],
      "metadata": {
        "id": "OZF4843A17HX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_best_feature(data, label):\n",
        "  features = data.drop(columns = [label])\n",
        "\n",
        "  features_info_gains = dict()\n",
        "\n",
        "  for feature in features:\n",
        "    features_info_gains[feature] = calculate_gain(feature, data, label)\n",
        "  \n",
        "  return max(features_info_gains, key=features_info_gains.get)"
      ],
      "metadata": {
        "id": "6c2o1mOLGtJF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_split(feature, data, label):\n",
        "  feature_values = data[feature].value_counts(sort=False)\n",
        "  tree = dict()\n",
        "\n",
        "  for feature_value, count in feature_values.items():\n",
        "    feature_value_data = data[data[feature] == feature_value]\n",
        "\n",
        "    pure_node = False\n",
        "    for i in np.unique(data[label]):\n",
        "      class_count = feature_value_data[feature_value_data[label] == i].shape[0]\n",
        "\n",
        "      if class_count == count:\n",
        "        tree[feature_value] = i\n",
        "        data = data[data[feature] != feature_value]\n",
        "        pure_node = True\n",
        "\n",
        "    if not pure_node:\n",
        "      tree[feature_value] = \"?\"\n",
        "    \n",
        "  return tree, data"
      ],
      "metadata": {
        "id": "e8KrE4_9X5G9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_tree(data, label, root, previous_feature):\n",
        "  if data.shape[0] != 0:\n",
        "    best_feature = find_best_feature(data, label)\n",
        "    tree, data = perform_split(best_feature, data, label)\n",
        "    next_root = None\n",
        "\n",
        "    if previous_feature != None:\n",
        "      root[previous_feature] = dict()\n",
        "      root[previous_feature][best_feature] = tree\n",
        "      next_root = root[previous_feature][best_feature]\n",
        "    else:\n",
        "      root[best_feature] = tree\n",
        "      next_root = root[best_feature]\n",
        "    \n",
        "    for node, branch in list(next_root.items()):\n",
        "      if branch == \"?\":\n",
        "        feature_value_data = data[data[best_feature] == node]\n",
        "        build_tree(feature_value_data, label, next_root, node)"
      ],
      "metadata": {
        "id": "rVum8HMYXXem"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def id3(data, label):\n",
        "  tree = dict()\n",
        "  build_tree(data, label, tree, None)\n",
        "  return tree"
      ],
      "metadata": {
        "id": "0hp1qQ9Eam7G"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(tree, instance):\n",
        "  if not isinstance(tree, dict):\n",
        "      return tree\n",
        "  else:\n",
        "      root_node = next(iter(tree))\n",
        "      feature_value = instance[root_node]\n",
        "      if feature_value in tree[root_node]:\n",
        "          return predict(tree[root_node][feature_value], instance)\n",
        "      else:\n",
        "          return None"
      ],
      "metadata": {
        "id": "Jdn9yN8VFNnN"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(tree, test_data, label):\n",
        "  correct_predict = 0\n",
        "  wrong_predict = 0\n",
        "  y_predicted = []\n",
        "  y_test = []\n",
        "  for i in range(test_data.shape[0] - 1):\n",
        "    result = predict(tree, test_data.iloc[i])\n",
        "    y_predicted.append(result)\n",
        "    y_test.append(test_data[label].iloc[i])\n",
        "    if result == test_data[label].iloc[i]:\n",
        "        correct_predict += 1\n",
        "    else:\n",
        "        wrong_predict += 1\n",
        "  accuracy = correct_predict / (correct_predict + wrong_predict)\n",
        "\n",
        "  #print(correct_predict)\n",
        "  #print(wrong_predict)\n",
        "  #print(y_predicted)\n",
        "  #print(y_test)\n",
        "  #conf_matrix = {'y_actual': y_test, 'y_predicted': y_predicted}\n",
        "\n",
        "  #df = pd.DataFrame(conf_matrix)\n",
        "\n",
        "  #confusion_matrix = pd.crosstab(df['y_actual'], df['y_predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
        "  #print(confusion_matrix)\n",
        "\n",
        "  print(\"Accuracy: \" + str(round(accuracy, 4) * 100) + \"%\")"
      ],
      "metadata": {
        "id": "flIlN4xTFbIa"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NpEncoder(json.JSONEncoder):\n",
        "  def default(self, obj):\n",
        "      if isinstance(obj, np.integer):\n",
        "          return int(obj)\n",
        "      if isinstance(obj, np.floating):\n",
        "          return float(obj)\n",
        "      if isinstance(obj, np.ndarray):\n",
        "          return obj.tolist()\n",
        "      return super(NpEncoder, self).default(obj)"
      ],
      "metadata": {
        "id": "DdiHTY8OvADP"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_graph(graph, dictionary, parent_node=None):\n",
        "  for key in dictionary.keys():\n",
        "      if parent_node is not None:\n",
        "          from_name = parent_node.get_name().replace(\"\\\"\", \"\") + '_' + str(key)\n",
        "          from_label = str(key)\n",
        "          obj_dict = {}\n",
        "          node_from = pydot.Node(from_name, label=from_label)\n",
        "          graph.add_node(node_from)\n",
        "          graph.add_edge( pydot.Edge(parent_node, node_from) )\n",
        "          if isinstance(dictionary[key], dict):\n",
        "              create_graph(graph, dictionary[key], node_from)\n",
        "          else:\n",
        "              to_name = str(uuid.uuid4()) + '_' + str(dictionary[key])\n",
        "              to_label = str(dictionary[key])\n",
        "              node_to = pydot.Node(to_name, label=to_label, shape='box')\n",
        "              graph.add_node(node_to)\n",
        "              graph.add_edge(pydot.Edge(node_from, node_to))\n",
        "      else:\n",
        "          from_name =  str(key)\n",
        "          from_label = str(key)\n",
        "          node_from = pydot.Node(from_name, label=from_label)\n",
        "          create_graph(graph, dictionary[key], node_from)"
      ],
      "metadata": {
        "id": "Ru4dKv4-vJO0"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_tree(tree, name):\n",
        "  graph = pydot.Dot(graph_type='graph')\n",
        "  create_graph(graph, tree)\n",
        "  graph.write_png(name+'.png')"
      ],
      "metadata": {
        "id": "QTlO2xewvKTL"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = read_data()\n",
        "data = data.astype(str)\n",
        "\n",
        "mask = np.random.rand(len(data)) < 0.66\n",
        "train_data = data[mask]\n",
        "test_data = data[~mask]\n",
        "\n",
        "#from sklearn.model_selection import train_test_split\n",
        "#train_data, test_data = train_test_split(data, test_size=0.25)\n",
        "#print(train_data)\n",
        "#print(test_data)\n",
        "\n",
        "label = \"Survived\"\n",
        "tree = id3(train_data, label)\n",
        "\n",
        "#print(json.dumps(tree, indent = 4, sort_keys=False, cls=NpEncoder))\n",
        "plot_tree(tree,'1')\n",
        "\n",
        "evaluate(tree, test_data, label)\n",
        "\n",
        "#Accuracies:\n",
        "#89.66%\n",
        "#85.71%\n",
        "#80.00%\n",
        "#91.88%\n",
        "#90.62%\n",
        "#86.21%\n",
        "#81.08%"
      ],
      "metadata": {
        "id": "Y5TiZjO14cXh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a55a8f49-be7e-4d40-af23-3f02f0a388ed"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 87.1%\n"
          ]
        }
      ]
    }
  ]
}